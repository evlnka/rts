# Отчет. Практическое задание 2 — Методы программирования в реальном времени для Linux

**Цель работы:** Изучить и применить на практике ключевые механизмы POSIX и Linux, используемые для разработки систем мягкого и жесткого реального времени.

**Задание 1: Анализ системных часов (`calctime1.c`, `calctime2.c`)**
- **Цель:** Понять разницу между `CLOCK_REALTIME` и `CLOCK_MONOTONIC`, научиться создавать стабильный периодический цикл с помощью `clock_nanosleep`.

- **Теория:** 
Типы системных часов\
- CLOCK_REALTIME - системное время, может изменяться скачкообразно (NTP, ручная настройка)
- CLOCK_MONOTONIC - монотонное время, гарантированно только увеличивается, идеально для измерения интервалов
Методы синхронизации\
- Относительный сон - накапливает ошибку от итерации к итерации
- Абсолютный сон (TIMER_ABSTIME) - предотвращает дрейф за счет привязки к идеальной временной сетке\

 **calctime1.c::**

Эта программа проверяет, насколько точно система может измерять время. Она много раз смотрит на системные часы и ждет, когда показания изменятся. Потом измеряет, сколько времени прошло между изменениями.\
\
Вывод calctime1.c:\
[![calctime1.png](https://i.postimg.cc/J7H3JWh0/calctime1.png)](https://postimg.cc/23mBRMhN)\

На практике программа показала, что система может заметить изменение времени от 30 наносекунд. Это очень маленькая величина - в 30 раз меньше микросекунды. Такую точность обеспечивают аппаратные таймеры компьютера.

Иногда программа показывала значения 90 наносекунд - это случается когда система занята другими задачами. В основном же результаты стабильно показывали 30-40 наносекунд.\

 **calctime2.c::**

Вторая программа проверяет, насколько точно система может выполнять задачи через равные промежутки времени. Мы заставили программу просыпаться каждые 2 миллисекунды и измеряли, насколько точно это получается.\

Вывод calctime2.c:\
[![calctime2.png](https://i.postimg.cc/wxR5JdBT/calctime2.png)](https://postimg.cc/XX3ySmFT)

Результаты показывают, что:
- В среднем пробуждение происходило через 2,000,090 наносекунд
- Самое короткое время было 1,199,142 наносекунд
- Самое долгое - 2,803,148 наносекунд
- Разброс значений составлял около 109,529 наносекунд

Первые 10 измерений показывают хорошую стабильность - все значения близки к 2 миллисекундам. Самый большой разброс был в шестом измерении (1,981,368 нс), но в целом система работает предсказуемо.

**Задание 2: Периодический таймер на `timerfd` (`reptimer_timerfd.c`)**
- **Цель:** Освоить современный Linux API (`timerfd`) для создания периодических событий без использования сигналов.

 **reptimer_timerfd.c - Первоначальная версия:**

Вывод creptimer_timerfd.c:\
[![reptimer1.png](https://i.postimg.cc/zDHwW1fD/reptimer1.png)](https://postimg.cc/s1yZdqSb)\
Эта версия показывала базовую работу timerfd, но не давала подробной информации о временных интервалах.


 **reptimer_timerfd.c - Улучшенная версия:**

Эта программа показывает современный способ создания таймеров в Linux. Вместо обычных функций сна мы используем специальный "файловый дескриптор таймера", который можно читать как обычный файл.\


Принцип работы:
1. Создаем таймер через timerfd_create()
2. Настраиваем его: первый запуск через 5 секунд, потом каждые 1.5 секунды
3. В цикле читаем из таймера командой read() - она ждет, пока таймер сработает
4. При каждом срабатывании выводим текущее время и счетчик

Вывод creptimer_timerfd.c:\
[![reptimer-timerfd.png](https://i.postimg.cc/rsrgVDsX/reptimer-timerfd.png)](https://postimg.cc/vxG5XH53)

Из результатов видно, что таймер срабатывает очень точно - интервалы между срабатываниями составляют примерно 1.5 секунды, как мы и задали.

Сравнение подходов clock_nanosleep и timerfd:\

clock_nanosleep:
- Блокирующий вызов, поток засыпает до указанного времени
- Простая реализация для одиночных периодических задач
- Точное время пробуждения с TIMER_ABSTIME
- Не интегрируется с другими I/O операциями\


timerfd:
- Представляет таймер как файловый дескриптор
- Неблокирующая интеграция с epoll, select, poll
- Можно ожидать несколько таймеров и сокетов одновременно
- Автоматическое накопление срабатываний при пропуске
- Лучше для сложных приложений с множеством I/O источнико\


timerfd предпочтительнее когда:
- Нужно интегрировать таймеры с сетевыми соединениями
- Множество таймеров должны обрабатываться в одном потоке
- Приложение использует event loop (epoll)
- Важно обрабатывать пропущенные срабатывания\

Timerfd - это мощный инструмент для сложных программ, где нужно управлять несколькими событиями одновременно. Он особенно полезен для сетевых приложений, где таймеры нужно комбинировать с работой с сокетами.\

Для простых задач подойдет clock_nanosleep, но для серьезных приложений timerfd с epoll дает гораздо больше возможностей.

### Таймауты, планировщик и техники минимизации задержек

**Задание 3: Стратегии обработки таймаутов (`timeout_*.c`)**
- **Цель:** Изучить три разных способа организации ожидания с таймаутом.

**timeout_poll.c - Ожидание на файловом дескрипторе:** 

Использует системный вызов poll() для мониторинга файловых дескрипторов с ограничением по времени.

Выполнение:
- Создается pipe для межпоточного взаимодействия
- Потребитель ожидает данные с таймаутом 300 мс → успешный таймаут
- Запускается поток-писатель, который через 200 мс записывает данные
- Потребитель повторно ожидает с таймаутом 1000 мс → успешное получение данных

Результат:\
[![timeout_poll.png](https://i.postimg.cc/PqZKmph7/timeout_poll.png)](https://postimg.cc/Jyrb8hs3)

- Строка 1-2: Читатель начинает ожидание на 300 мс и получает ожидаемый таймаут - подтверждает, что pipe изначально пустой
- Строка 3: Читатель запускает писателя и начинает новое ожидание на 1000 мс
- Строка 4-5: Писатель засыпает на 200 мс, затем записывает данные в pipe
- Строка 6-7: Читатель обнаруживает данные, читает байт 'X' в пределах таймаута

**timeout_condvar.c - Межпоточное ожидание на условных переменных:** 

Использует комбинацию мьютексов и условных переменных для синхронизации потоков с возможностью таймаута.

с
- Потребитель ожидает сигнал на условной переменной с таймаутом 100 мс → успешный таймаут
- Запускается поток-производитель, который через 200 мс сигнализирует условную переменную
- Потребитель ожидает с таймаутом 1000 мс → неожиданный таймаут

Результат:\
[![timeout_condvar.png](https://i.postimg.cc/bvbLQD8C/timeout_condvar.png)](https://postimg.cc/PLXmHqCY)

- Строка 1-2: Потребитель ожидает 100 мс и получает таймаут - условная переменная не сигнализирована
- Строка 3-4: Потребитель запускает производителя и ждет 1000 мс, но получает неожиданный таймаут
- Строка 5-6: Производитель спит 200 мс и сигнализирует условие, но потребитель уже завершил ожидание

**timeout_mq.c - Межпроцессное ожидание на очередях сообщений:** 

Использует POSIX message queues с функцией mq_timedreceive() для ожидания сообщений с таймаутом.

Выполнение:
- Потребитель ожидает сообщение из пустой очереди с таймаутом 100 мс → успешный таймаут
- Запускается поток-отправитель, который через 300 мс отправляет сообщение
- Потребитель ожидает с таймаутом 1000 мс → успешное получение сообщения

Результат:\
[![timeout_mq.png](https://i.postimg.cc/25vT4bmX/timeout_mq.png)](https://postimg.cc/HJYQmLrQ)

- Строка 1-2: Получатель ждет 100 мс на пустой очереди и получает ожидаемый таймаут
- Строка 3: Получатель запускает отправителя и начинает ожидание на 1000 мс
- Строка 4-5: Отправитель спит 300 мс и отправляет сообщение
- Строка 6: Получатель успешно получает сообщение "hello" в пределах таймаута

**ttimeout_ppoll.c - Безопасное ожидание с обработкой сигналов:** 

Использует ppoll() для атомарной разблокировки сигналов во время ожидания, решая проблему race condition.

Выполнение:
- Основной поток блокирует сигнал SIGUSR1
- Создается поток-отправитель, который через 1 секунду отправляет сигнал
- Основной поток вызывает ppoll() с временной разблокировкой сигнала
- Сигнал успешно прерывает ожидание и выполняется обработчик

Результат:\
[![timeout_ppoll.png](https://i.postimg.cc/HL53QcH6/timeout_ppoll.png)](https://postimg.cc/xkfKQdXm)

- Строка 1: Основной поток блокирует SIGUSR1
- Строка 2: Вызывается ppoll() с разблокированной маской сигналов
- Строка 3-4: Отправитель спит 1 секунду и отправляет SIGUSR1
- Строка 5: Обработчик сигнала выполняется - доказательство работы механизма
- Строка 6-7: ppoll() корректно прерван сигналом, обработчик выполнен

Все изученные механизмы таймаутов успешно выполняют свои задачи в соответствующих областях применения. Наиболее надежными показали себя poll() для работы с файловыми дескрипторами и ppoll() для безопасной обработки сигналов. Механизм условных переменных требует наибольшей аккуратности при реализации due to проблем синхронизации.

**Задание 4: Оптимизация для реального времени (`sched_fifo_jitter.c`)**
- **Цель:** Измерить джиттер планировщика и применить техники для его уменьшения.

**sched_fifo_jitter.c - Без изменений:** 

Программа запущена под стандартным планировщиком без каких-либо оптимизаций.

Результат:\
[![sched.png](https://i.postimg.cc/vm8ySVHH/sched.png)](https://postimg.cc/TKsBKhDZ)

- Средний джиттер: 193,215 наносекунд 
- 99-й процентиль: 514,750 наносекунд 
- Максимальный джиттер: 2,046,113 наносекунд 
- Минимальный джиттер: 53,078 наносекунд 

**sched_fifo_jitter.c - Дополненный:** 

Программа запущена с правами root с применением всех оптимизаций.

Результат:\
[![sched2.png](https://i.postimg.cc/htL4YnLs/sched2.png)](https://postimg.cc/87CVFqnf)

- Средний джиттер: 80,409 наносекунд 
- 99-й процентиль: 437,099 наносекунд 
- Максимальный джиттер: 553,234 наносекунд 
- Минимальный джиттер: 4,430 наносекунд 

Улучшение производительности:
- Средний джиттер уменьшен в 2.4 раза - с 193.2 до 80.4 микросекунды
- 99-й процентиль улучшен в 1.2 раза - с 514.8 до 437.1 микросекунды
- Максимальный джиттер сокращен в 3.7 раза - с 2046.1 до 553.2 микросекунды
- Минимальный джиттер улучшен в 12 раз - с 53.1 до 4.4 микросекунды\

Объяснение влияния техник на уменьшение джиттера:
 
 1. SCHED_FIFO планировщик (наибольший вклад):
- Исключает вытеснение обычными процессами (SCHED_OTHER)
- Гарантирует немедленное выполнение после пробуждения из clock_nanosleep()
- Устраняет недетерминизм планировщика CFS (Completely Fair Scheduler)
- Приоритет 50 обеспечивает доминирование над системными процессами
- Эффект: Уменьшил максимальный джиттер с 2.05 мс до 0.55 мс
 
2. Блокировка памяти (mlockall) - критично для детерминизма:
- Предотвращает вытеснение страниц памяти процесса в swap
- Устраняет задержки, вызванные page faults (до 10+ мс)
- Исключает паузы на подкачку страниц с диска
- MCL_CURRENT блокирует текущие страницы памяти
- MCL_FUTURE блокирует все будущие выделения памяти
- Эффект: Стабилизировал минимальный джиттер (улучшение в 12 раз)

3. Привязка к ядру CPU - улучшает стабильность:
- Закрепляет поток на CPU 11 (последнее ядро)
- Сохраняет кэш процессора (L1, L2, L3) - исключает промахи кэша примиграции
- Предотвращает TLB misses - сохраняет буферы ассоциативной трансляции
- Исключает межъядерные задержки синхронизации
- Изолирует от влияния других процессов на выбранном ядре
- Эффект: Улучшил средний джиттер и стабильность измерений

 Комбинация трех техник дала значительное улучшение, особенно в максимальном джиттере.

---


## Сборка и запуск

Для сборки всех примеров используйте `Makefile` в каталоге `tasks/task2`:
```bash
make
```
Бинарные файлы будут созданы в директории `bin/`.

## Контрольные вопросы

1.  **Сравнение `clock_nanosleep` и `nanosleep`**: Почему для периодических задач в СРВ `clock_nanosleep` с абсолютным временем всегда предпочтительнее, чем относительный `nanosleep`? Проиллюстрируйте проблему накопления ошибки на гипотетическом примере.\

Проблема относительного сна (nanosleep) заключается в кумулятивном накоплении ошибки.


struct timespec interval = {0, 2000000}; // 2ms\
for (int i = 0; i < 5; i++) {\
    // Фактическое время сна: 2ms + ошибка_сна(i)\
    nanosleep(&interval, NULL);\
    // Время выполнения кода: время_кода(i)\
    // Общая ошибка итерации: ошибка_сна(i) + время_кода(i)\
}\
// Общее время: 5*2ms + Σ(ошибка_сна(i) + время_кода(i))\

Решение с clock_nanosleep и абсолютным временем:\
struct timespec next;\
clock_gettime(CLOCK_MONOTONIC, &next);\
for (int i = 0; i < 5; i++) {\
    next.tv_nsec += 2000000; // 2ms\
    clock_nanosleep(CLOCK_MONOTONIC, TIMER_ABSTIME, &next, NULL);\
    // Каждое пробуждение привязано к своей ячейке: T0, T0+2ms, T0+4ms...\
}\
// Ошибка не накапливается: каждая итерация независима\

Если каждая итерация имеет ошибку +100 мкс, то за 100 циклов относительный сон накопит 10 мс ошибки, в то время как абсолютный сон сохранит ошибку в пределах ±100 мкс.

2.  **`timerfd` vs Сигналы**: POSIX-таймеры (`timer_create`) могут доставлять события через сигналы. Почему `timerfd` считается более надежным и предсказуемым механизмом для построения циклов обработки событий (event loops)?

Проблемы POSIX-таймеров с сигналами:
- Race condition: Сигнал может прийти между проверкой флага и блокирующим вызовом
- Ограничения обработчиков: Можно использовать только async-signal-safe функции
- Сложность отладки: Асинхронное выполнение усложняет диагностику

Преимущества timerfd:
- Синхронный интерфейс: Обычные операции read()
- Интеграция с event loop: Совместимость с poll/epoll/select
- Простота использования: Не требует обработчиков сигналов
- Учет пропусков: read() возвращает количество пропущенных срабатываний


3.  **Инверсия приоритетов**: Хотя мы не реализовывали это напрямую, опишите сценарий, в котором использование `pthread_mutex` может привести к инверсии приоритетов. Какие атрибуты мьютекса (см. `pthread_mutexattr_setprotocol`) помогают решить эту проблему?

Сценарий инверсии приоритетов:
- Низкоприоритетная задача L захватывает мьютекс
- Высокоприоритетная задача H пытается захватить мьютекс и блокируется
- Среднеприоритетная задача M вытесняет L
- Результат: H блокируется M, хотя имеет более высокий приоритет

Протоколы:
- PTHREAD_PRIO_INHERIT: Владелец временно получает приоритет ждущих задач
- PTHREAD_PRIO_PROTECT: Владелец всегда выполняется с заданным приоритетом
- PTHREAD_PRIO_NONE: Без специальной обработки (по умолчанию)

4.  **Предсказуемость vs Производительность**: Объясните, почему техники, использованные в задании 4 (`SCHED_FIFO`, привязка к ядру), могут *уменьшить* общую производительность системы, но при этом *повысить* ее предсказуемость.

Почему уменьшается производительность:
- SCHED_FIFO: Real-time задачи могут монополизировать CPU, вызывая голодание системных процессов
- Привязка к ядру: Неравномерное распределение нагрузки, некоторые ядра могут простаивать
- Блокировка памяти: Уменьшает доступную память для других процессов

Почему повышается предсказуемость:
- Исключаются недетерминированные задержки планировщика
- Гарантируется время отклика для критических задач
- Устраняется влияние других процессов на выполнение

5.  **Жесткое реальное время**: Достаточно ли рассмотренных техник для построения системы жесткого реального времени на стандартном ядре Linux? Что такое `PREEMPT_RT` и какие фундаментальные изменения в ядре он вносит для обеспечения детерминизма?

Ограничения стандартного ядра Linux:
- Невытесняемые секции ядра: Длинные критические секции с отключенными прерываниями
- Спин-блокировки: Могут приводить к неопределенным задержкам
- Планировщик CFS: Оптимизирован для throughput, а не latency

PREEMPT_RT - это патч ядра Linux, который вносит фундаментальные изменения:
- Полная вытесняемость ядра: Большинство операций ядра становятся вытесняемыми
- Замена спин-блокировок: На мьютексы с приоритетным наследованием
- Threaded interrupts: Обработчики прерываний выполняются как обычные потоки
- Улучшенный планировщик: Оптимизирован для минимальной latency